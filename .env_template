# ===============================
# MODEL & TRAINING CONFIGURATION
# ===============================

# Base model name (pretrained transformer)
MODEL_NAME=distilbert-base-uncased

# Model storage/output configuration
MODEL_NAME_DIR=customer-support-distilbert
MODEL_VERSION=1.0.0
MODEL_OUTPUT_BASE_FOLDER_NAME=aws_service_training_dataset_classification
MODEL_OUTPUT_BASE_FOLDER_NAME_CLUSTERING=aws_service_training_dataset_clustering
MODELS_OUTPUT_DIR=outputs/model_outputs
MODELS_OUTPUT_DIR_CLUSTERING=outputs/model_outputs/clustering
MODELS_OUTPUT_DIR_CLASSIFICATION=outputs/model_outputs/classification
DATA_LEAKAGE_OUTPUT_DIR=outputs/model_outputs/classification/customer-support-distilbert/1.0.0/data_leakage_detection
MODEL_OUTPUT_BASE_FOLDER_NAME_CLASSIFICATION=aws_service_training_dataset_classification

# ===============================
# TRAINING HYPERPARAMETERS
# ===============================

# Number of training epochs
TRAIN_NUM_EPOCHS=3

# Batch sizes for training and evaluation
TRAIN_BATCH_SIZE=4
EVAL_BATCH_SIZE=8

# Learning rate and weight decay
TRAIN_LEARNING_RATE=5e-5
TRAIN_WEIGHT_DECAY=0.01

# Warmup steps for learning rate scheduler
TRAIN_WARMUP_STEPS=100

# ===============================
# DATASET CONFIGURATION
# ===============================
# Not Skipped Worksheets: Amazon_S3
DATASET_WORKSHEETS_TO_SKIP_CSV="Amazon_EC2,Amazon_RDS,Amazon_VPC,Amazon_DynamoDB,AWS_Lambda,Amazon_VPC,Amazon_Redshift,Amazon_Kinesis,Amazon_ElastiCache,AWS_IAM,AWS_CloudFormation,AWS_CloudTrail,AWS_Config,Amazon_SNS,Amazon_SQS,AWS_Step_Functions,AWS_Glue,Amazon_SageMaker,AWS_Fargate,Amazon_EKS,AWS_WAF,AWS_Shield,Amazon_CloudFront,AWS_Direct_Connect,Amazon_EFS"
DATASET_CATEGORIES="Billing,Technical Support,Account Management,General Inquiry"
DATASET_EXCEL_COLUMN_NAMES="category,category_serial_number,sample_question,sample_question_type"

# Columns to actually use for model training (subset of above)
DATASET_COLUMN_NAMES_FOR_TRAINING="category,sample_question,sample_question_type"

# Excel file settings
TRAINING_DATASET_EXCEL_FILE_PATH="../z_datasets/training_datasets/aws_services_questions"
TRAINING_DATASET_EXCEL_FILE_NAMES_CSV="aws_service_training_dataset.xlsx"
TRAINING_DATASET_EXCEL_FILE_LOCATION="LOCAL_FILE_SYSTEM"

# ===============================
# PIPELINE METADATA
# ===============================
TRAINING_ENABLE_CLASSIFICATION=true
TRAINING_PIPELINE_NAME="CustomerSupportFineTuningTrainingPipeline"
TRAINING_PIPELINE_DISPLAY_NAME="Customer Support DistilBERT Training Pipeline"
TRAINING_JOB_DISPLAY_NAME=customer_support_distilbert_training_job
TRAINING_PIPELINE_WORKFLOWS_JSON_PATH="../aws_data_fine_tuning_pipeline_wfs.json"

# Label column(s)
#TRAINING_DATASET_LABELS2IDS_COLUMN_NAMES_CSV="category"
TRAINING_DATASET_CLASSIFICATION_COLUMN_NAMES_CSV="category"

# Dataset split ratios
TRAINING_DATASET_TRAIN_RATIO=80
TRAINING_DATASET_TEST_RATIO=20

# ===============================
# CLUSTERING CONFIGURATION
# ===============================

# Enable or disable clustering workflow
TRAINING_ENABLE_CLUSTERING=true

# Columns to use for clustering text (comma-separated)
# e.g. cluster by both question and type
# Why category was not included by default
# When clustering, you’re usually trying to discover natural groupings in your data without using known labels.
# So if category is below classification label (e.g. “Billing”, “Technical Support”), including it as a text feature can actually bias or leak supervision into your unsupervised clustering.
TRAINING_DATASET_CLUSTERING_TEXT_COLUMNS_CSV="sample_question,sample_question_type"

# Number of clusters to form (if algorithm supports it)
TRAINING_CLUSTERING_NUM_CLUSTERS=5

# Algorithm choice: kmeans | hdbscan | dbscan | agglomerative
TRAINING_CLUSTERING_ALGORITHM=kmeans

# Optional: dimensionality reduction before clustering (none|pca|umap)
TRAINING_CLUSTERING_DIM_REDUCTION=umap

# Output directory for clustering artifacts
TRAINING_CLUSTERING_OUTPUT_DIR=../outputs/clustering_results

# Clustering distance metric
TRAINING_CLUSTERING_DISTANCE_METRIC=cosine

# Minimum cluster size (for HDBSCAN or DBSCAN)
TRAINING_CLUSTERING_MIN_CLUSTER_SIZE=5

# Random seed for reproducibility
TRAINING_CLUSTERING_RANDOM_STATE=42

